// Copyright (c) 2023
// Commonwealth Scientific and Industrial Research Organisation (CSIRO)
// ABN 41 687 119 230
//
// Author: Jules Helper

#include "raylib/raycloud.h"
#include "raylib/rayparse.h"
#include "raylib/rayply.h" // Added for chunked PLY writing
#include <nabo/nabo.h>      // For Nabo C++ interface, Nabo::NNSearchD, Nabo::runtime_error
#include <stdexcept>      // For std::runtime_error (though Nabo might have its own)
#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <cmath>
#include <memory>           // For std::unique_ptr
#include <algorithm>        // For std::min, std::max
#include <numeric>          // For std::iota (if used, currently not)
#include <deque>            // For potential use in buffer management, though starting with vector
#include <Eigen/Eigenvalues> // For PCA-based normal estimation
#include <limits>           // For std::numeric_limits
#include <cstdio>           // For std::remove (deleting intermediate file)

// Forward declaration for progress reporter if its definition is not included
// Assuming a dummy or basic ray::Progress might exist or be defined elsewhere if used.
// For this integration, detailed progress reporting is secondary to structural setup.
namespace ray {
    class Progress { // Minimal dummy definition if not available
    public:
        void begin(const std::string&, size_t) {}
        void increment() {}
        void end() {}
    };
}


// Define the struct to hold all uncertainty components
struct UncertaintyComponents {
    double total_v;     // Total variance
    double range_v;     // Range uncertainty component
    double angular_v;   // Angular uncertainty component
    double aoi_v;       // Angle of incidence uncertainty component
    double mixed_pixel_v; // New component
};

// TEMPORARY: Assume common defaults if raylibconfig.h isn't easily included by a tool's cpp directly.
// This should ideally come from a config header.
#ifndef RAYLIB_DOUBLE_RAYS
#define RAYLIB_DOUBLE_RAYS 0 // common default
#endif
#ifndef RAYLIB_WITH_NORMAL_FIELD
#define RAYLIB_WITH_NORMAL_FIELD 1 // common default
#endif

bool saveRayCloudWithUncertainty(
    const std::string& file_name,
    const ray::Cloud& cloud,
    const std::vector<UncertaintyComponents>& all_uncertainties)
{
    if (cloud.rayCount() == 0) {
        std::ofstream ofs(file_name, std::ios::binary | std::ios::out);
        if (!ofs) {
            std::cerr << "Error: Cannot open " << file_name << " for writing." << std::endl;
            return false;
        }
        ofs << "ply" << std::endl;
        ofs << "format binary_little_endian 1.0" << std::endl;
        ofs << "comment generated by raynoise tool - empty cloud" << std::endl;
        ofs << "element vertex 0" << std::endl;
#if RAYLIB_DOUBLE_RAYS
        ofs << "property double x" << std::endl;
        ofs << "property double y" << std::endl;
        ofs << "property double z" << std::endl;
#else
        ofs << "property float x" << std::endl;
        ofs << "property float y" << std::endl;
        ofs << "property float z" << std::endl;
#endif
        ofs << "property double time" << std::endl;
#if RAYLIB_WITH_NORMAL_FIELD
        ofs << "property float nx" << std::endl;
        ofs << "property float ny" << std::endl;
        ofs << "property float nz" << std::endl;
#else
        ofs << "property float rayx" << std::endl;
        ofs << "property float rayy" << std::endl;
        ofs << "property float rayz" << std::endl;
#endif
        ofs << "property uchar red" << std::endl;
        ofs << "property uchar green" << std::endl;
        ofs << "property uchar blue" << std::endl;
        ofs << "property uchar alpha" << std::endl;
        ofs << "property double total_variance" << std::endl;
        ofs << "property double range_variance" << std::endl;
        ofs << "property double angular_variance" << std::endl;
        ofs << "property double aoi_variance" << std::endl;
        ofs << "property double mixed_pixel_variance" << std::endl;
        ofs << "end_header" << std::endl;
        ofs.close();
        return true;
    }

    if (cloud.rayCount() != all_uncertainties.size()) {
        std::cerr << "Error: Mismatch between point cloud size (" << cloud.rayCount()
                  << ") and uncertainties vector size (" << all_uncertainties.size() << ")." << std::endl;
        return false;
    }

    std::ofstream ofs(file_name, std::ios::binary | std::ios::out);
    if (!ofs) {
        std::cerr << "Error: Cannot open " << file_name << " for writing." << std::endl;
        return false;
    }

    ofs << "ply" << std::endl;
    ofs << "format binary_little_endian 1.0" << std::endl;
    ofs << "comment generated by raynoise tool" << std::endl;
    ofs << "element vertex " << cloud.rayCount() << std::endl;

#if RAYLIB_DOUBLE_RAYS
    ofs << "property double x" << std::endl;
    ofs << "property double y" << std::endl;
    ofs << "property double z" << std::endl;
    using coord_type = double;
#else
    ofs << "property float x" << std::endl;
    ofs << "property float y" << std::endl;
    ofs << "property float z" << std::endl;
    using coord_type = float;
#endif

    ofs << "property double time" << std::endl;

#if RAYLIB_WITH_NORMAL_FIELD
    ofs << "property float nx" << std::endl;
    ofs << "property float ny" << std::endl;
    ofs << "property float nz" << std::endl;
#else
    ofs << "property float rayx" << std::endl;
    ofs << "property float rayy" << std::endl;
    ofs << "property float rayz" << std::endl;
#endif
    using ray_comp_type = float;

    ofs << "property uchar red" << std::endl;
    ofs << "property uchar green" << std::endl;
    ofs << "property uchar blue" << std::endl;
    ofs << "property uchar alpha" << std::endl;

    ofs << "property double total_variance" << std::endl;
    ofs << "property double range_variance" << std::endl;
    ofs << "property double angular_variance" << std::endl;
    ofs << "property double aoi_variance" << std::endl;
    ofs << "property double mixed_pixel_variance" << std::endl;
    using uncertainty_comp_type = double;

    ofs << "end_header" << std::endl;

    for (size_t i = 0; i < cloud.rayCount(); ++i) {
        coord_type px = static_cast<coord_type>(cloud.ends[i].x());
        coord_type py = static_cast<coord_type>(cloud.ends[i].y());
        coord_type pz = static_cast<coord_type>(cloud.ends[i].z());
        ofs.write(reinterpret_cast<const char*>(&px), sizeof(coord_type));
        ofs.write(reinterpret_cast<const char*>(&py), sizeof(coord_type));
        ofs.write(reinterpret_cast<const char*>(&pz), sizeof(coord_type));

        double time_val = cloud.times[i];
        ofs.write(reinterpret_cast<const char*>(&time_val), sizeof(double));

        Eigen::Vector3d ray_vec = cloud.starts[i] - cloud.ends[i];
        ray_comp_type rvx = static_cast<ray_comp_type>(ray_vec.x());
        ray_comp_type rvy = static_cast<ray_comp_type>(ray_vec.y());
        ray_comp_type rvz = static_cast<ray_comp_type>(ray_vec.z());
        ofs.write(reinterpret_cast<const char*>(&rvx), sizeof(ray_comp_type));
        ofs.write(reinterpret_cast<const char*>(&rvy), sizeof(ray_comp_type));
        ofs.write(reinterpret_cast<const char*>(&rvz), sizeof(ray_comp_type));

        ofs.write(reinterpret_cast<const char*>(&cloud.colours[i].red), sizeof(uint8_t));
        ofs.write(reinterpret_cast<const char*>(&cloud.colours[i].green), sizeof(uint8_t));
        ofs.write(reinterpret_cast<const char*>(&cloud.colours[i].blue), sizeof(uint8_t));
        ofs.write(reinterpret_cast<const char*>(&cloud.colours[i].alpha), sizeof(uint8_t));

        uncertainty_comp_type total_v_val = all_uncertainties[i].total_v;
        uncertainty_comp_type range_v_val = all_uncertainties[i].range_v;
        uncertainty_comp_type angular_v_val = all_uncertainties[i].angular_v;
        uncertainty_comp_type aoi_v_val = all_uncertainties[i].aoi_v;
        uncertainty_comp_type mixed_v_val = all_uncertainties[i].mixed_pixel_v;

        ofs.write(reinterpret_cast<const char*>(&total_v_val), sizeof(uncertainty_comp_type));
        ofs.write(reinterpret_cast<const char*>(&range_v_val), sizeof(uncertainty_comp_type));
        ofs.write(reinterpret_cast<const char*>(&angular_v_val), sizeof(uncertainty_comp_type));
        ofs.write(reinterpret_cast<const char*>(&aoi_v_val), sizeof(uncertainty_comp_type));
        ofs.write(reinterpret_cast<const char*>(&mixed_v_val), sizeof(uncertainty_comp_type));

        if (!ofs.good()) {
            std::cerr << "Error: Failed to write data for point " << i << " to " << file_name << std::endl;
            ofs.close();
            return false;
        }
    }

    ofs.close();
    std::cout << "Successfully saved point cloud with detailed uncertainties (including mixed pixel) to " << file_name << std::endl;
    return true;
}

std::vector<UncertaintyComponents> CalculatePointUncertainty(
    const ray::Cloud& pointCloud,
    double base_range_accuracy,
    double base_angle_accuracy,
    double c_intensity,
    double epsilon,
    double c_aoi,
    double epsilon_aoi,
    int k_mixed_neighbors,
    double depth_threshold_mixed,
    int min_front_neighbors_mixed,
    int min_behind_neighbors_mixed,
    double variance_mixed_pixel_penalty,
    bool is_chunked_mode = false,
    const std::vector<Eigen::Vector3d>* pass1_normals_ptr = nullptr)
{
    static bool aoi_warning_issued = false; // For chunked mode without precomputed normals
    static bool mixed_pixel_warning_issued_pass2 = false; // Specific for Pass 2's mixed pixel
    static bool pass1_normals_usage_info_issued = false;

    std::vector<UncertaintyComponents> all_uncertainties;
    if (pointCloud.rayCount() == 0) {
        return all_uncertainties;
    }
    all_uncertainties.reserve(pointCloud.rayCount());

    double base_range_variance = std::pow(base_range_accuracy, 2);
    double base_angle_variance = std::pow(base_angle_accuracy, 2);

    // --- Normal Generation ---
    std::vector<Eigen::Vector3d> surface_normals;
    bool normals_valid = false;

    bool normals_already_provided = (pass1_normals_ptr != nullptr && !pass1_normals_ptr->empty());
    if (normals_already_provided) {
        surface_normals = *pass1_normals_ptr;
        normals_valid = (surface_normals.size() == pointCloud.rayCount());
        if (!normals_valid) {
            std::cerr << "Warning: Mismatch between point count (" << pointCloud.rayCount()
                      << ") and provided Pass 1 normal count (" << surface_normals.size()
                      << "). AoI may be affected." << std::endl;
        } else {
            if (!pass1_normals_usage_info_issued) {
                 std::cout << "Info: Using pre-computed Pass 1 normals for AoI calculation." << std::endl;
                 pass1_normals_usage_info_issued = true;
            }
        }
    } else if (is_chunked_mode) {
        // This is Phase 1 chunked mode OR Pass 2 chunked mode IF pass1_normals_ptr was null/empty.
        // The latter case should ideally not happen if Pass 2 is invoked correctly.
        if (!aoi_warning_issued) {
            std::cout << "Warning: Chunked mode active AND no pre-computed normals provided. AoI calculation is simplified (using fallback), potentially impacting accuracy. AoI variance may be less precise." << std::endl;
            aoi_warning_issued = true;
        }
        // Normals_valid remains false, AoI will use fallback.
    } else {
        // Non-chunked mode (original full cloud processing)
        const int default_normal_search_size = 16;
        if (pointCloud.rayCount() > static_cast<size_t>(default_normal_search_size)) {
            ray::Cloud tempCloud = pointCloud; // Make a mutable copy for generateNormals
            surface_normals = tempCloud.generateNormals(default_normal_search_size);
            if (surface_normals.size() == pointCloud.rayCount()) {
                normals_valid = true;
            } else {
                std::cerr << "Warning: Normal generation (default k) returned " << surface_normals.size()
                          << " normals for " << pointCloud.rayCount()
                          << " points. AoI component may be inaccurate." << std::endl;
            }
        } else if (pointCloud.rayCount() > 1) {
            ray::Cloud tempCloud = pointCloud; // Make a mutable copy
            int adaptive_search_size = std::max(1, static_cast<int>(pointCloud.rayCount()) - 1);
            surface_normals = tempCloud.generateNormals(adaptive_search_size);
            if (surface_normals.size() == pointCloud.rayCount()) {
                normals_valid = true;
            } else {
                std::cerr << "Warning: Normal generation (adaptive k) returned " << surface_normals.size()
                          << " normals for " << pointCloud.rayCount()
                          << " points. AoI component may be inaccurate." << std::endl;
            }
        } else {
            if (pointCloud.rayCount() > 0) {
                 std::cerr << "Warning: Only " << pointCloud.rayCount()
                           << " point(s) in cloud. Cannot generate reliable surface normals. AoI component will use fallback." << std::endl;
            }
        }
    }

    // --- Mixed Pixel Detection Setup ---
    std::unique_ptr<Nabo::NNSearchD> nns;
    if (is_chunked_mode) { // This applies to Phase 1 simple chunking AND Pass 2 chunking
        if (!mixed_pixel_warning_issued_pass2) { // Use a more specific flag if behavior differs by pass
            std::cout << "Warning: Mixed Pixel detection in chunked mode is performed locally within each processing chunk, which may not capture all large-scale neighborhood effects. Its variance contribution might be zero if no local mixed pixels are found or if k_mixed_neighbors is too small for the chunk." << std::endl;
            mixed_pixel_warning_issued_pass2 = true;
        }
        // For Pass 2 (and Phase 1 simple chunking), NNS is built per-chunk.
        // This was the original behavior for "is_chunked_mode" before two-pass was introduced.
        // The "disabled" message was for Phase 1's CalculatePointUncertainty call.
        // Now, for Pass 2, it *is* calculated but on a per-chunk basis.
        // The following logic for NNS setup will run if k_mixed_neighbors > 0.
        // If pass1_normals_ptr is present, it implies Pass 2.
        // If is_chunked_mode is true (which it is for Pass 2):
        // The NNS will be built from pointCloud (which is a single chunk in Pass 2).
        // This is different from Pass 1 global normal calculation.
        // So, the warning should reflect that mixed pixel is *local* to the chunk.
        // The original "disabled" message for mixed_pixel_warning_issued (the general one) might still be relevant if
        // is_chunked_mode is true AND pass1_normals_ptr is null (i.e. old Phase 1 path).
        // Let's ensure the old `mixed_pixel_warning_issued` is used for the old path,
        // and `mixed_pixel_warning_issued_pass2` for the new path.
        // The current code uses a single `mixed_pixel_warning_issued`.
        // Let's refine this:
        if (pass1_normals_ptr == nullptr && !aoi_warning_issued) { // Original Phase 1 chunking (no pass1 normals)
             static bool original_chunked_mixed_pixel_warning = false;
             if(!original_chunked_mixed_pixel_warning){
                std::cout << "Warning: Original chunked mode (no Pass 1 normals). Mixed Pixel detection is simplified/local to chunk." << std::endl;
                original_chunked_mixed_pixel_warning = true;
             }
        }
        // The actual NNS setup for per-chunk mixed pixel (applies to Pass 2 and original chunked mode):
        Eigen::MatrixXd cloud_matrix_eigen;
        if (k_mixed_neighbors > 0 && pointCloud.rayCount() > static_cast<size_t>(k_mixed_neighbors)) {
            cloud_matrix_eigen.resize(3, pointCloud.rayCount());
            for (size_t pt_idx = 0; pt_idx < pointCloud.rayCount(); ++pt_idx) {
                cloud_matrix_eigen.col(pt_idx) = pointCloud.ends[pt_idx];
            }
            try {
                nns.reset(Nabo::NNSearchD::createKDTreeLinearHeap(cloud_matrix_eigen));
            } catch (const std::runtime_error& e) { // Changed to std::runtime_error
                std::cerr << "Nabo KD-tree creation failed (caught as std::runtime_error): " << e.what() << std::endl;
                nns.reset();
            }
        }
    }

    for (size_t i = 0; i < pointCloud.rayCount(); ++i) {
        const Eigen::Vector3d& point_pos = pointCloud.ends[i];
        const Eigen::Vector3d& origin_pos = pointCloud.starts[i];

        Eigen::Vector3d d_vec = point_pos - origin_pos;
        double range_squared = d_vec.squaredNorm();

        uint8_t alpha_intensity = pointCloud.colours[i].alpha;
        float normalized_intensity = static_cast<float>(alpha_intensity) / 255.0f;
        double intensity_term = normalized_intensity + epsilon;
        if (intensity_term <= 0) { intensity_term = epsilon; }

        double current_range_v = base_range_variance * (1.0 + c_intensity / intensity_term);
        double current_angular_v = range_squared * base_angle_variance;
        double current_aoi_v = 0.0;

        if (normals_valid) {
            Eigen::Vector3d ray_vector_aoi = point_pos - origin_pos;
            if (ray_vector_aoi.squaredNorm() < 1e-12) {
                current_aoi_v = c_aoi / epsilon_aoi;
            } else {
                Eigen::Vector3d normalized_ray_dir_aoi = ray_vector_aoi.normalized();
                const Eigen::Vector3d& surface_normal_at_point = surface_normals[i];
                if (surface_normal_at_point.squaredNorm() < 1e-12) {
                    current_aoi_v = c_aoi / epsilon_aoi;
                } else {
                    Eigen::Vector3d normalized_surface_normal = surface_normal_at_point.normalized();
                    double cos_theta = std::abs(normalized_ray_dir_aoi.dot(normalized_surface_normal));
                    current_aoi_v = c_aoi / (cos_theta + epsilon_aoi);
                }
            }
        } else {
            current_aoi_v = c_aoi / epsilon_aoi;
        }

        double current_mixed_pixel_v = 0.0;
        if (nns) {
            Eigen::VectorXi indices(k_mixed_neighbors + 1);
            Eigen::VectorXd dists2(k_mixed_neighbors + 1);
            Eigen::Vector3d query_point = pointCloud.ends[i];

            try {
                nns->knn(query_point, indices, dists2, k_mixed_neighbors + 1);

                Eigen::Vector3d ray_P_i = pointCloud.ends[i] - pointCloud.starts[i];
                double ray_P_i_norm = ray_P_i.norm();
                Eigen::Vector3d normalized_ray_P_i;
                bool ray_P_i_is_valid = (ray_P_i_norm > 1e-9);

                if(ray_P_i_is_valid) {
                    normalized_ray_P_i = ray_P_i / ray_P_i_norm;
                    int count_front = 0;
                    int count_behind = 0;
                    for (int k_idx = 0; k_idx < k_mixed_neighbors + 1; ++k_idx) {
                        int neighbor_idx = indices(k_idx);
                        if (static_cast<size_t>(neighbor_idx) == i) continue;

                        Eigen::Vector3d vec_origin_Pi_to_Pj_end = pointCloud.ends[neighbor_idx] - pointCloud.starts[i];
                        double depth_Pj_on_rayPi = vec_origin_Pi_to_Pj_end.dot(normalized_ray_P_i);
                        double depth_Pi_on_rayPi = ray_P_i_norm;
                        double depth_diff = depth_Pj_on_rayPi - depth_Pi_on_rayPi;

                        if (depth_diff < -depth_threshold_mixed) {
                            count_front++;
                        }
                        if (depth_diff > depth_threshold_mixed) {
                            count_behind++;
                        }
                    }
                    if (count_front >= min_front_neighbors_mixed && count_behind >= min_behind_neighbors_mixed) {
                        current_mixed_pixel_v = variance_mixed_pixel_penalty;
                    }
                }
            } catch (const std::runtime_error& e) { // Changed to std::runtime_error
                std::cerr << "Nabo kNN search failed for point " << i << " (caught as std::runtime_error): " << e.what() << std::endl;
            }
        }

        double current_total_v = current_range_v + current_angular_v + current_aoi_v + current_mixed_pixel_v;
        all_uncertainties.push_back({current_total_v, current_range_v, current_angular_v, current_aoi_v, current_mixed_pixel_v});
    }
    return all_uncertainties;
}

void print_usage(int exit_code = 1) {
    // clang-format off
    std::cout << "raynoise: Calculates positional uncertainty for point cloud data." << std::endl;
    std::cout << "Usage: raynoise <input_file> <output_file> [options]" << std::endl;
    std::cout << std::endl;
    std::cout << "Required arguments:" << std::endl;
    std::cout << "  <input_file>          Input point cloud file (PLY or LAZ)" << std::endl;
    std::cout << "  <output_file>         Output point cloud file with uncertainty" << std::endl;
    std::cout << std::endl;
    std::cout << "Options:" << std::endl;
    std::cout << "  --base_range_accuracy <value> (-r <value>)" << std::endl;
    std::cout << "                        Sensor's base 1-sigma range accuracy (m). Default: 0.02" << std::endl;
    std::cout << "  --base_angle_accuracy <value> (-a <value>)" << std::endl;
    std::cout << "                        Sensor's base 1-sigma angular accuracy (rad). Default: 0.0035" << std::endl;
    std::cout << "  --c_intensity <value> (-c <value>)" << std::endl;
    std::cout << "                        Coefficient for intensity effect. Default: 0.5" << std::endl;
    std::cout << "  --epsilon <value> (-e <value>)" << std::endl;
    std::cout << "                        Small value for intensity division (intensity term). Default: 0.01" << std::endl;
    std::cout << "  --c_aoi <value>" << std::endl;
    std::cout << "                        Coefficient for angle of incidence effect. Default: 0.1" << std::endl;
    std::cout << "  --epsilon_aoi <value>" << std::endl;
    std::cout << "                        Small value for angle of incidence division. Default: 0.01" << std::endl;
    std::cout << "  --k_mixed <value>" << std::endl;
    std::cout << "                        Number of neighbors for mixed pixel detection. Default: 8" << std::endl;
    std::cout << "  --depth_thresh_mixed <value>" << std::endl;
    std::cout << "                        Depth threshold for mixed pixel detection (m). Default: 0.05" << std::endl;
    std::cout << "  --min_front_mixed <value>" << std::endl;
    std::cout << "                        Min front neighbors for mixed pixel detection. Default: 1" << std::endl;
    std::cout << "  --min_behind_mixed <value>" << std::endl;
    std::cout << "                        Min behind neighbors for mixed pixel detection. Default: 1" << std::endl;
    std::cout << "  --penalty_mixed <value>" << std::endl;
    std::cout << "                        Variance penalty for detected mixed pixels (m^2). Default: 0.5" << std::endl;
    std::cout << "  --chunk_size <value>" << std::endl;
    std::cout << "                        Process points in chunks. If > 0, activates a two-pass mode for large files:" << std::endl;
    std::cout << "                          Pass 1: Computes robust surface normals across the dataset by processing" << std::endl;
    std::cout << "                                  overlapping blocks of points and stores data in a temporary file." << std::endl;
    std::cout << "                                  This allows for accurate Angle of Incidence (AoI) later." << std::endl;
    std::cout << "                          Pass 2: Reads the intermediate file (with normals) in chunks of <value> size," << std::endl;
    std::cout << "                                  calculates all uncertainty components, and writes the final output." << std::endl;
    std::cout << "                        In this two-pass mode, Mixed Pixel detection is performed locally within" << std::endl;
    std::cout << "                        each chunk in Pass 2. Parameters for Pass 1 normal estimation (k-neighbors," << std::endl;
    std::cout << "                        block size, overlap) currently use internal defaults." << std::endl;
    std::cout << "                        If 0, uses original single-pass, full-load processing. Default: 0." << std::endl;
    std::cout << "  --help (-h)           Print this usage message." << std::endl;
    // clang-format on
    exit(exit_code);
}

// Forward declarations
bool executePass1_GenerateNormalsAndIntermediatePly(
    const std::string& input_ply_file,
    const std::string& intermediate_ply_file,
    int k_for_normals,
    size_t primary_block_size,
    size_t overlap_size,
    ray::Progress& progress_reporter
);

bool executePass2_CalculateUncertainty(
    const std::string& intermediate_ply_file,
    const std::string& final_output_ply_file,
    double base_range_accuracy, double base_angle_accuracy,
    double c_intensity, double epsilon,
    double c_aoi, double epsilon_aoi,
    int k_mixed_neighbors, double depth_threshold_mixed,
    int min_front_neighbors_mixed, int min_behind_neighbors_mixed,
    double variance_mixed_pixel_penalty,
    size_t chunk_size_pass2,
    ray::Progress& progress_reporter
);

int rayNoiseMain(int argc, char* argv[]) {
    ray::FileArgument inputFile;
    ray::FileArgument outputFile;

    ray::DoubleArgument baseRangeAccuracyArg(0.0, 10.0, 0.02);
    ray::DoubleArgument baseAngleAccuracyArg(0.0, 1.0, 0.0035);
    ray::DoubleArgument cIntensityArg(0.0, 100.0, 0.5);
    ray::DoubleArgument epsilonArg(1e-9, 1.0, 0.01);
    ray::DoubleArgument cAoiArg(0.0, 10.0, 0.1);
    ray::DoubleArgument epsilonAoiArg(1e-9, 1.0, 0.01);

    ray::IntArgument kMixedNeighborsArg(1, 50, 8);
    ray::DoubleArgument depthThreshMixedArg(0.001, 10.0, 0.05);
    ray::IntArgument minFrontMixedArg(1, 50, 1);
    ray::IntArgument minBehindMixedArg(1, 50, 1);
    ray::DoubleArgument penaltyMixedArg(0.0, 100.0, 0.5);
    ray::IntArgument chunkSizeArg(0, 10000000, 0); // Min 0 (off), Max 10M, Default 0

    ray::OptionalFlagArgument helpFlag("help", 'h');
    ray::OptionalKeyValueArgument baseRangeOpt("base_range_accuracy", 'r', &baseRangeAccuracyArg);
    ray::OptionalKeyValueArgument baseAngleOpt("base_angle_accuracy", 'a', &baseAngleAccuracyArg);
    ray::OptionalKeyValueArgument cIntensityOpt("c_intensity", 'c', &cIntensityArg);
    ray::OptionalKeyValueArgument epsilonOpt("epsilon", 'e', &epsilonArg);
    ray::OptionalKeyValueArgument cAoiOpt("c_aoi", '\0', &cAoiArg);
    ray::OptionalKeyValueArgument epsilonAoiOpt("epsilon_aoi", '\0', &epsilonAoiArg);
    ray::OptionalKeyValueArgument kMixedOpt("k_mixed", '\0', &kMixedNeighborsArg);
    ray::OptionalKeyValueArgument depthThreshMixedOpt("depth_thresh_mixed", '\0', &depthThreshMixedArg);
    ray::OptionalKeyValueArgument minFrontMixedOpt("min_front_mixed", '\0', &minFrontMixedArg);
    ray::OptionalKeyValueArgument minBehindMixedOpt("min_behind_mixed", '\0', &minBehindMixedArg);
    ray::OptionalKeyValueArgument penaltyMixedOpt("penalty_mixed", '\0', &penaltyMixedArg);
    ray::OptionalKeyValueArgument chunkSizeOpt("chunk_size", '\0', &chunkSizeArg);

    std::vector<ray::FixedArgument*> fixedArgs = {&inputFile, &outputFile};
    std::vector<ray::OptionalArgument*> optionalArgs = {
        &helpFlag, &baseRangeOpt, &baseAngleOpt, &cIntensityOpt, &epsilonOpt,
        &cAoiOpt, &epsilonAoiOpt,
        &kMixedOpt, &depthThreshMixedOpt, &minFrontMixedOpt, &minBehindMixedOpt, &penaltyMixedOpt,
        &chunkSizeOpt
    };

    if (!ray::parseCommandLine(argc, argv, fixedArgs, optionalArgs)) {
        if (argc == 1 || helpFlag.isSet()) {
             print_usage(0);
        }
        print_usage(1);
    }
     if (helpFlag.isSet()) {
        print_usage(0);
    }

    std::string input_file_str = inputFile.name();
    std::string output_file_str = outputFile.name();

    double base_range_accuracy = baseRangeAccuracyArg.value();
    double base_angle_accuracy = baseAngleAccuracyArg.value();
    double c_intensity = cIntensityArg.value();
    double epsilon = epsilonArg.value();
    double c_aoi = cAoiArg.value();
    double epsilon_aoi = epsilonAoiArg.value();
    int k_mixed_neighbors = kMixedNeighborsArg.value();
    double depth_threshold_mixed = depthThreshMixedArg.value();
    int min_front_neighbors_mixed = minFrontMixedArg.value();
    int min_behind_neighbors_mixed = minBehindMixedArg.value();
    double variance_mixed_pixel_penalty = penaltyMixedArg.value();
    int chunk_size = chunkSizeArg.value();

    if (epsilon <= 0 || epsilon_aoi <= 0 || depth_threshold_mixed <=0) {
        std::cerr << "Error: Epsilon values (epsilon, epsilon_aoi) and depth_threshold_mixed must be positive." << std::endl;
        print_usage(1);
    }
    if (k_mixed_neighbors <= 0 || min_front_neighbors_mixed <=0 || min_behind_neighbors_mixed <=0) {
        std::cerr << "Error: Neighbor counts (k_mixed, min_front_mixed, min_behind_mixed) must be positive." << std::endl;
        print_usage(1);
    }
    if (chunk_size < 0) { // Should be caught by IntArgument min, but good practice.
        std::cerr << "Error: chunk_size must be non-negative." << std::endl;
        print_usage(1);
    }

    if (chunk_size > 0) {
        // Two-pass chunked strategy
        std::cout << "Two-pass chunked processing initiated for input: " << input_file_str << std::endl;
        std::string intermediate_ply_file = input_file_str + ".pass1_normals.tmp.ply";

        // Parameters for Pass 1 normal generation
        // TODO: Make these configurable via command line if needed
        int k_for_normals_pass1 = k_mixed_neighbors; // Use k_mixed as a proxy, or define new param
        if (k_for_normals_pass1 < 3) k_for_normals_pass1 = 3; // Ensure k is at least 3 for PCA
        size_t primary_block_size_pass1 = 200000;
        size_t overlap_size_pass1 = std::max(static_cast<size_t>(k_for_normals_pass1 * 10), static_cast<size_t>(2000)); // Heuristic for overlap

        ray::Progress progress_reporter; // Dummy progress reporter for now

        bool pass1_success = executePass1_GenerateNormalsAndIntermediatePly(
            input_file_str,
            intermediate_ply_file,
            k_for_normals_pass1,
            primary_block_size_pass1,
            overlap_size_pass1,
            progress_reporter
        );

        if (!pass1_success) {
            std::cerr << "Error: Pass 1 (Normal Estimation) failed. Aborting." << std::endl;
            std::remove(intermediate_ply_file.c_str()); // Attempt to clean up
            return 1;
        }
        std::cout << "Pass 1 (Normal Estimation) completed. Intermediate file: " << intermediate_ply_file << std::endl;
        std::cout << "Starting Pass 2 (Uncertainty Calculation using Pass 1 normals)..." << std::endl;

        // Pass 2: Calculate uncertainty using normals from intermediate file
        // chunk_size here is the user-provided --chunk_size, controlling Pass 2's own chunking behavior.
        bool pass2_success = executePass2_CalculateUncertainty(
            intermediate_ply_file,
            output_file_str,
            base_range_accuracy, base_angle_accuracy,
            c_intensity, epsilon, c_aoi, epsilon_aoi,
            k_mixed_neighbors, depth_threshold_mixed,
            min_front_neighbors_mixed, min_behind_neighbors_mixed,
            variance_mixed_pixel_penalty,
            chunk_size, // User's chunk_size for Pass 2 read/write chunking
            progress_reporter
        );

        if (!pass2_success) {
            std::cerr << "Error: Pass 2 (Uncertainty Calculation) failed." << std::endl;
            std::cerr << "Intermediate file with Pass 1 normals kept for debugging: " << intermediate_ply_file << std::endl;
            return 1;
        }

        // If both passes succeed, delete the intermediate file
        if (std::remove(intermediate_ply_file.c_str()) != 0) {
            std::cerr << "Warning: Could not delete intermediate file: " << intermediate_ply_file << std::endl;
        } else {
            std::cout << "Successfully deleted intermediate file: " << intermediate_ply_file << std::endl;
        }

        std::cout << "Two-pass chunked processing completed successfully." << std::endl;

    } else {
        // Original Single-Pass (Non-Chunked) Logic
        // This path is taken if --chunk_size is 0 (or not provided)
        std::cout << "Single-pass (non-chunked) processing." << std::endl;
        ray::Cloud pointCloud;
        if (!pointCloud.load(input_file_str, true, 0)) {
            std::cerr << "Error: Could not load point cloud from " << input_file_str << std::endl;
            return 1;
        }

        if (pointCloud.rayCount() == 0) {
            std::cout << "Input point cloud is empty (non-chunked path)." << std::endl;
            std::vector<UncertaintyComponents> empty_uncertainties;
            if (!saveRayCloudWithUncertainty(output_file_str, pointCloud, empty_uncertainties)) {
                 std::cerr << "Error: Failed to save empty point cloud header." << std::endl;
                 return 1;
            }
            std::cout << "Saved empty PLY with headers to " << output_file_str << std::endl;
            return 0;
        }

        if (pointCloud.starts.size() != pointCloud.rayCount() ||
            pointCloud.ends.size() != pointCloud.rayCount() ||
            pointCloud.colours.size() != pointCloud.rayCount() ||
            pointCloud.times.size() != pointCloud.rayCount()) {
            std::cerr << "Error: Inconsistent data sizes in loaded point cloud." << std::endl;
            return 1;
        }

        std::vector<UncertaintyComponents> uncertainties = CalculatePointUncertainty(
            pointCloud, base_range_accuracy, base_angle_accuracy, c_intensity, epsilon,
            c_aoi, epsilon_aoi,
            k_mixed_neighbors, depth_threshold_mixed, min_front_neighbors_mixed,
            min_behind_neighbors_mixed, variance_mixed_pixel_penalty,
            false, /* is_chunked_mode */
            nullptr /* pass1_normals_ptr */);

        if (!saveRayCloudWithUncertainty(output_file_str, pointCloud, uncertainties)) {
            std::cerr << "Error: Failed to save point cloud with uncertainty to " << output_file_str << std::endl;
            return 1;
        }
    }

    return 0;
}

int main(int argc, char* argv[]) {
    return rayNoiseMain(argc, argv);
}


// Pass 1: Read input PLY, generate normals with overlap, write to intermediate PLY
// (Implementation from previous step - assumed correct and complete)
bool executePass1_GenerateNormalsAndIntermediatePly(
    const std::string& input_ply_file,
    const std::string& intermediate_ply_file,
    int k_for_normals, // k for k-NN normal estimation
    size_t primary_block_size, // Number of points in a primary block
    size_t overlap_size, // Number of points for overlap on each side
    ray::Progress& /*progress_reporter*/) // Existing declaration is fine


// Pass 2: Read intermediate PLY (with Pass 1 normals), calculate uncertainty, write final PLY
bool executePass2_CalculateUncertainty(
    const std::string& intermediate_ply_file,
    const std::string& final_output_ply_file,
    // Pass relevant raynoise parameters needed for CalculatePointUncertainty
    double base_range_accuracy, double base_angle_accuracy,
    double c_intensity, double epsilon,
    double c_aoi, double epsilon_aoi,
    int k_mixed_neighbors, double depth_threshold_mixed,
    int min_front_neighbors_mixed, int min_behind_neighbors_mixed,
    double variance_mixed_pixel_penalty,
    size_t chunk_size_pass2, // Chunk size for reading intermediate and processing in Pass 2
    ray::Progress& /*progress_reporter*/) // TODO: Integrate progress reporting
{
    std::cout << "Starting Pass 2: Calculating uncertainty using Pass 1 normals." << std::endl;
    std::cout << "  Intermediate Input: " << intermediate_ply_file << std::endl;
    std::cout << "  Final Output: " << final_output_ply_file << std::endl;

    std::ofstream out_final_ply_stream;
    out_final_ply_stream.open(final_output_ply_file, std::ios::binary | std::ios::out);
    if (!out_final_ply_stream) {
        std::cerr << "Error: Cannot open final output file " << final_output_ply_file << " for writing." << std::endl;
        return false;
    }

    unsigned long vertex_count_pos_pass2 = 0;
    if (!ray::writeRayNoisePlyHeader(out_final_ply_stream, vertex_count_pos_pass2)) {
        std::cerr << "Error: Failed to write PLY header to final output file " << final_output_ply_file << std::endl;
        out_final_ply_stream.close();
        return false;
    }

    unsigned long total_points_written_pass2 = 0;
    bool pass2_chunk_write_error = false;

    auto apply_chunk_pass2_lambda =
        [&](std::vector<Eigen::Vector3d>& starts_orig,
            std::vector<Eigen::Vector3d>& ends_orig,
            std::vector<double>& times_orig,
            std::vector<ray::RGBA>& colours_orig,
            std::vector<Eigen::Vector3d>& pass1_normals_chunk) {

        if (pass2_chunk_write_error) return;
        if (ends_orig.empty()) {
            std::cout << "Pass 2 lambda received empty chunk." << std::endl;
            return;
        }

        ray::Cloud chunk_cloud_for_calc;
        // For CalculatePointUncertainty, starts and ends are original sensor/point positions
        chunk_cloud_for_calc.starts = std::move(starts_orig);
        chunk_cloud_for_calc.ends = std::move(ends_orig);
        chunk_cloud_for_calc.times = std::move(times_orig);
        chunk_cloud_for_calc.colours = std::move(colours_orig);
        // Ensure rayCount is implicitly set if ray::Cloud relies on it internally,
        // or explicitly set it if needed. For now, assuming member vector sizes are used.
        // chunk_cloud_for_calc.setRayCount(chunk_cloud_for_calc.ends.size()); // If such a method exists/is needed

        // Call CalculatePointUncertainty with Pass 1 normals
        // is_chunked_mode = true for Pass 2 so Mixed Pixel uses its simplified logic (intra-chunk k-NN)
        // unless a more advanced inter-chunk Mixed Pixel is developed for Pass 2.
        std::vector<UncertaintyComponents> chunk_uncertainties = CalculatePointUncertainty(
            chunk_cloud_for_calc, base_range_accuracy, base_angle_accuracy,
            c_intensity, epsilon, c_aoi, epsilon_aoi,
            k_mixed_neighbors, depth_threshold_mixed,
            min_front_neighbors_mixed, min_behind_neighbors_mixed,
            variance_mixed_pixel_penalty,
            true, /* is_chunked_mode for Pass 2 */
            &pass1_normals_chunk);

        std::vector<ray::RayNoiseUncertaintyData> rayply_uncertainties;
        rayply_uncertainties.reserve(chunk_uncertainties.size());
        for (const auto& src_unc : chunk_uncertainties) {
            rayply_uncertainties.push_back({src_unc.total_v, src_unc.range_v, src_unc.angular_v, src_unc.aoi_v, src_unc.mixed_pixel_v});
        }

        // Prepare a ray::Cloud for writing the final PLY.
        // The nx,ny,nz fields in the final PLY should be the Pass 1 normals.
        // ray::writeRayNoisePlyChunk writes (cloud.starts[i] - cloud.ends[i]) as the normal/ray vector.
        // So, we need to set cloud.starts[i] = cloud.ends[i] + pass1_normals_chunk[i].
        ray::Cloud chunk_cloud_for_writing;
        chunk_cloud_for_writing.ends = chunk_cloud_for_calc.ends; // These were moved into chunk_cloud_for_calc, need to get them back or copy earlier
                                                                // Corrected: use the vectors received by lambda as they are distinct after move from chunk_cloud_for_calc
        chunk_cloud_for_writing.times = chunk_cloud_for_calc.times;
        chunk_cloud_for_writing.colours = chunk_cloud_for_calc.colours;
        // Re-populate .ends from chunk_cloud_for_calc as it's the owner now
        // Or, more simply, use the original ends_orig (which is now chunk_cloud_for_calc.ends)
        // For clarity, let's use the members of chunk_cloud_for_calc

        chunk_cloud_for_writing.starts.resize(chunk_cloud_for_calc.ends.size());
        for(size_t i = 0; i < chunk_cloud_for_calc.ends.size(); ++i) {
            chunk_cloud_for_writing.starts[i] = chunk_cloud_for_calc.ends[i] + pass1_normals_chunk[i];
        }
        // The original ends were moved to chunk_cloud_for_calc.ends.
        // We need to ensure chunk_cloud_for_writing.ends gets these values.
        // Assigning chunk_cloud_for_calc.ends to chunk_cloud_for_writing.ends is fine.

        if (!ray::writeRayNoisePlyChunk(out_final_ply_stream,
                                     chunk_cloud_for_writing.starts, // These are effectively end_point + pass1_normal
                                     chunk_cloud_for_calc.ends,      // These are the actual point end coordinates
                                     chunk_cloud_for_calc.times,
                                     chunk_cloud_for_calc.colours,
                                     rayply_uncertainties)) {
            std::cerr << "Error: Failed to write chunk to final output file." << std::endl;
            pass2_chunk_write_error = true;
        } else {
            total_points_written_pass2 += chunk_cloud_for_calc.ends.size();
        }
    };

    bool read_pass2_success = ray::readPlyForPass2(
        intermediate_ply_file,
        apply_chunk_pass2_lambda,
        0.0, /* max_intensity - not critical for intermediate's alpha */
        false, /* times_optional */
        chunk_size_pass2);

    if (!read_pass2_success && !pass2_chunk_write_error) {
        std::cerr << "Error: readPlyForPass2 failed for intermediate file: " << intermediate_ply_file << std::endl;
        out_final_ply_stream.close();
        return false;
    }
    if (pass2_chunk_write_error) {
        std::cerr << "Error occurred during Pass 2 chunk writing." << std::endl;
        out_final_ply_stream.close();
        return false;
    }

    if (!ray::finalizeRayNoisePlyHeader(out_final_ply_stream, total_points_written_pass2, vertex_count_pos_pass2)) {
        std::cerr << "Error: Failed to finalize PLY header for final output file." << std::endl;
        out_final_ply_stream.close();
        return false;
    }

    out_final_ply_stream.close();
    std::cout << "Pass 2 completed. Total points written to final output file: " << total_points_written_pass2 << std::endl;
    return true;
}


// Pass 1: Read input PLY, generate normals with overlap, write to intermediate PLY
// (Implementation from previous step - assumed correct and complete)
bool executePass1_GenerateNormalsAndIntermediatePly(
    const std::string& input_ply_file,
    const std::string& intermediate_ply_file,
    int k_for_normals, // k for k-NN normal estimation
    size_t primary_block_size, // Number of points in a primary block
    size_t overlap_size, // Number of points for overlap on each side
    ray::Progress& /*progress_reporter*/) // TODO: Integrate progress reporting
{
    std::cout << "Starting Pass 1: Generating normals and writing intermediate PLY." << std::endl;
    std::cout << "  Input: " << input_ply_file << std::endl;
    std::cout << "  Intermediate Output: " << intermediate_ply_file << std::endl;
    std::cout << "  K for normals: " << k_for_normals << std::endl;
    std::cout << "  Primary block size: " << primary_block_size << std::endl;
    std::cout << "  Overlap size: " << overlap_size << std::endl;

    std::ofstream out_intermediate_stream;
    out_intermediate_stream.open(intermediate_ply_file, std::ios::binary | std::ios::out);
    if (!out_intermediate_stream) {
        std::cerr << "Error: Cannot open intermediate file " << intermediate_ply_file << " for writing." << std::endl;
        return false;
    }

    unsigned long intermediate_vertex_count_pos = 0;
    if (!ray::writeIntermediatePass1PlyHeader(out_intermediate_stream, intermediate_vertex_count_pos)) {
        std::cerr << "Error: Failed to write PLY header to intermediate file " << intermediate_ply_file << std::endl;
        out_intermediate_stream.close();
        return false;
    }

    unsigned long total_points_written_pass1 = 0;
    bool pass1_error_occurred = false;

    // Buffers for managing overlaps and primary data blocks
    // Using std::vector for now. std::deque might be more efficient for remove-from-front,
    // but given fixed block processing, vector move/copy might be okay.
    std::vector<Eigen::Vector3d> starts_prev_overlap, ends_prev_overlap;
    std::vector<double> times_prev_overlap;
    std::vector<ray::RGBA> colours_prev_overlap;

    std::vector<Eigen::Vector3d> starts_curr_primary, ends_curr_primary;
    std::vector<double> times_curr_primary;
    std::vector<ray::RGBA> colours_curr_primary;

    std::vector<Eigen::Vector3d> starts_next_overlap_accum, ends_next_overlap_accum;
    std::vector<double> times_next_overlap_accum;
    std::vector<ray::RGBA> colours_next_overlap_accum;

    std::vector<Eigen::Vector3d> normals_for_primary_block; // To store computed normals

    // State variables for the lambda
    size_t points_in_curr_primary_buf = 0;
    size_t points_in_next_overlap_buf = 0;
    bool first_block_processed = false; // Tracks if we've processed the very first primary block.
                                      // Renamed from is_first_block to avoid confusion as it changes after first block.

    size_t input_chunk_offset = 0; // Tracks current position within the incoming chunk from readPly

    // This lambda orchestrates filling buffers and triggering normal computation + writing
    auto process_block_for_normals_lambda =
        [&](std::vector<Eigen::Vector3d>& chunk_starts,
            std::vector<Eigen::Vector3d>& chunk_ends,
            std::vector<double>& chunk_times, // Ensure this is std::vector<double>
            std::vector<ray::RGBA>& chunk_colours,
            bool is_final_chunk_from_readply) { // readPly needs to signal this

        if (pass1_error_occurred) return;

        std::cout << "  Lambda received chunk of size: " << chunk_ends.size()
                  << (is_final_chunk_from_readply ? " (final chunk)" : "") << std::endl;
        input_chunk_offset = 0;

        while(input_chunk_offset < chunk_ends.size()) {
            // Fill current primary block buffer
            if (points_in_curr_primary_buf < primary_block_size) {
                size_t can_add_to_primary = primary_block_size - points_in_curr_primary_buf;
                size_t remaining_in_chunk = chunk_ends.size() - input_chunk_offset;
                size_t num_to_add = std::min(can_add_to_primary, remaining_in_chunk);

                starts_curr_primary.insert(starts_curr_primary.end(), chunk_starts.begin() + input_chunk_offset, chunk_starts.begin() + input_chunk_offset + num_to_add);
                ends_curr_primary.insert(ends_curr_primary.end(), chunk_ends.begin() + input_chunk_offset, chunk_ends.begin() + input_chunk_offset + num_to_add);
                // Ensure data from chunk_times (std::vector<double>) is inserted into times_curr_primary (std::vector<double>)
                times_curr_primary.insert(times_curr_primary.end(), chunk_times.begin() + input_chunk_offset, chunk_times.begin() + input_chunk_offset + num_to_add);
                colours_curr_primary.insert(colours_curr_primary.end(), chunk_colours.begin() + input_chunk_offset, chunk_colours.begin() + input_chunk_offset + num_to_add);

                points_in_curr_primary_buf += num_to_add;
                input_chunk_offset += num_to_add;
            }

            // Fill next overlap buffer accumulator
            if (points_in_curr_primary_buf == primary_block_size && points_in_next_overlap_buf < overlap_size) {
                 size_t can_add_to_overlap = overlap_size - points_in_next_overlap_buf;
                 size_t remaining_in_chunk = chunk_ends.size() - input_chunk_offset;
                 size_t num_to_add = std::min(can_add_to_overlap, remaining_in_chunk);

                starts_next_overlap_accum.insert(starts_next_overlap_accum.end(), chunk_starts.begin() + input_chunk_offset, chunk_starts.begin() + input_chunk_offset + num_to_add);
                ends_next_overlap_accum.insert(ends_next_overlap_accum.end(), chunk_ends.begin() + input_chunk_offset, chunk_ends.begin() + input_chunk_offset + num_to_add);
                // Ensure data from chunk_times (std::vector<double>) is inserted into times_next_overlap_accum (std::vector<double>)
                times_next_overlap_accum.insert(times_next_overlap_accum.end(), chunk_times.begin() + input_chunk_offset, chunk_times.begin() + input_chunk_offset + num_to_add);
                colours_next_overlap_accum.insert(colours_next_overlap_accum.end(), chunk_colours.begin() + input_chunk_offset, chunk_colours.begin() + input_chunk_offset + num_to_add);

                points_in_next_overlap_buf += num_to_add;
                input_chunk_offset += num_to_add;
            }

            // Check if a block is ready for processing
            bool ready_to_process_block = (points_in_curr_primary_buf == primary_block_size &&
                                          (points_in_next_overlap_buf == overlap_size || is_final_chunk_from_readply));

            if (is_final_chunk_from_readply && input_chunk_offset == chunk_ends.size() && points_in_curr_primary_buf > 0 && !ready_to_process_block) {
                 // This is the very end of the file, and current primary is not full but has data.
                 // It needs to be processed as the last block.
                 ready_to_process_block = true;
            }


            if (ready_to_process_block) {
                std::cout << "  Processing block. Primary size: " << ends_curr_primary.size()
                          << ", Prev Overlap: " << ends_prev_overlap.size()
                          << ", Next Overlap (Accum): " << ends_next_overlap_accum.size() << std::endl;

                // --- Actual Normal Computation ---
                size_t n_prev = ends_prev_overlap.size();
                size_t n_curr = ends_curr_primary.size();
                size_t n_next = ends_next_overlap_accum.size();
                size_t total_points_in_combined_block = n_prev + n_curr + n_next;

                normals_for_primary_block.assign(n_curr, Eigen::Vector3d(0,0,1)); // Default normal if anything fails

                if (total_points_in_combined_block < 3 || n_curr == 0) {
                    std::cerr << "Warning (Pass 1): Not enough points in combined block (" << total_points_in_combined_block
                              << ") or current primary block is empty (" << n_curr
                              << ") to compute normals. Using default normals for this primary block." << std::endl;
                    // normals_for_primary_block is already default. Proceed to write.
                } else {
                    Eigen::MatrixXd processing_block_matrix(3, total_points_in_combined_block);
                    size_t col_idx = 0;
                    for (const auto& pt : ends_prev_overlap) processing_block_matrix.col(col_idx++) = pt;
                    for (const auto& pt : ends_curr_primary) processing_block_matrix.col(col_idx++) = pt;
                    for (const auto& pt : ends_next_overlap_accum) processing_block_matrix.col(col_idx++) = pt;

                    std::unique_ptr<Nabo::NNSearchD> nns;
                    try {
                        nns.reset(Nabo::NNSearchD::createKDTreeLinearHeap(processing_block_matrix));
                    } catch (const std::runtime_error& e) {
                        std::cerr << "Nabo KD-tree creation failed in Pass 1: " << e.what()
                                  << ". Using default normals for this block." << std::endl;
                        // normals_for_primary_block is already default. Allow processing to continue with these.
                        // No need to set pass1_error_occurred as this is a local failure for this block's normals.
                    }

                    if (nns) { // Only proceed if KD-tree was successfully built
                        static bool insufficient_neighbors_warning_issued_pass1 = false;
                        for (size_t i = 0; i < n_curr; ++i) {
                            // const Eigen::Vector3d& current_query_point = ends_curr_primary[i]; // Unused

                            Eigen::VectorXi indices_eigen(k_for_normals);
                            Eigen::VectorXd dists2_eigen(k_for_normals);

                            // Query point index in processing_block_matrix is n_prev + i
                            nns->knn(processing_block_matrix.col(n_prev + i), indices_eigen, dists2_eigen, k_for_normals, 1e-9, Nabo::NNSearchD::ALLOW_SELF_MATCH);

                            int num_found_neighbors = 0;
                            for (int k = 0; k < k_for_normals; ++k) {
                                if (dists2_eigen(k) != std::numeric_limits<double>::infinity()) {
                                    num_found_neighbors++;
                                } else {
                                    break;
                                }
                            }

                            if (num_found_neighbors < 3) {
                                if (!insufficient_neighbors_warning_issued_pass1) {
                                    std::cerr << "Warning (Pass 1): Insufficient neighbors (" << num_found_neighbors
                                              << " found, need at least 3) for point " << (total_points_written_pass1 + i)
                                              << ". Using default normal (0,0,1). This message appears once per run." << std::endl;
                                    insufficient_neighbors_warning_issued_pass1 = true;
                                }
                                normals_for_primary_block[i] = Eigen::Vector3d(0,0,1); // Already default, but explicit
                                continue;
                            }

                            Eigen::MatrixXd neighbor_points(3, num_found_neighbors);
                            for (int k = 0; k < num_found_neighbors; ++k) {
                                neighbor_points.col(k) = processing_block_matrix.col(indices_eigen(k));
                            }

                            Eigen::Vector3d centroid = neighbor_points.rowwise().mean();
                            Eigen::MatrixXd centered_neighbors = neighbor_points.colwise() - centroid;
                            Eigen::Matrix3d covariance_matrix = centered_neighbors * centered_neighbors.transpose() / num_found_neighbors;

                            Eigen::SelfAdjointEigenSolver<Eigen::Matrix3d> eigensolver(covariance_matrix, Eigen::ComputeEigenvectors);
                            if (eigensolver.info() != Eigen::Success) {
                                normals_for_primary_block[i] = Eigen::Vector3d(0,0,1); // Default on solver failure
                                continue;
                            }
                            Eigen::Vector3d normal = eigensolver.eigenvectors().col(0); // Smallest eigenvalue's eigenvector

                            // Orient normal
                            Eigen::Vector3d ray_vector = starts_curr_primary[i] - ends_curr_primary[i];
                            if (ray_vector.squaredNorm() > 1e-12) {
                                if (normal.dot(ray_vector.normalized()) < 0) {
                                    normal = -normal;
                                }
                            } else { // Fallback for zero-length ray vector
                                if (normal.z() < 0) { // Simplistic orientation towards positive Z
                                    normal = -normal;
                                }
                            }
                            normals_for_primary_block[i] = normal.normalized(); // Ensure unit normal
                        }
                    }
                }
                // --- End Actual Normal Computation ---

                if (!ray::writeIntermediatePass1PlyChunk(out_intermediate_stream,
                                                       starts_curr_primary, ends_curr_primary,
                                                       times_curr_primary, colours_curr_primary,
                                                       normals_for_primary_block)) {
                    std::cerr << "Error: Failed to write intermediate PLY chunk." << std::endl;
                    pass1_error_occurred = true;
                    return; // Stop further processing in lambda
                }
                total_points_written_pass1 += ends_curr_primary.size();
                std::cout << "    Written " << ends_curr_primary.size() << " points to intermediate file. Total written: " << total_points_written_pass1 << std::endl;

                // Buffer shifting logic:
                // Current primary's end becomes new previous overlap
                starts_prev_overlap.clear(); ends_prev_overlap.clear(); times_prev_overlap.clear(); colours_prev_overlap.clear();
                if (overlap_size > 0 && ends_curr_primary.size() >= overlap_size) { // Ensure curr_primary is large enough
                    size_t start_idx = ends_curr_primary.size() - overlap_size;
                    starts_prev_overlap.assign(starts_curr_primary.begin() + start_idx, starts_curr_primary.end());
                    ends_prev_overlap.assign(ends_curr_primary.begin() + start_idx, ends_curr_primary.end());
                    // Ensure times_curr_primary (std::vector<double>) is assigned to times_prev_overlap (std::vector<double>)
                    times_prev_overlap.assign(times_curr_primary.begin() + start_idx, times_curr_primary.end());
                    colours_prev_overlap.assign(colours_curr_primary.begin() + start_idx, colours_curr_primary.end());
                } else if (overlap_size > 0) { // curr_primary is smaller than overlap_size (e.g. end of file)
                     starts_prev_overlap = starts_curr_primary; // take all of it
                     ends_prev_overlap = ends_curr_primary;
                     // Ensure times_curr_primary (std::vector<double>) is assigned to times_prev_overlap (std::vector<double>)
                     times_prev_overlap = times_curr_primary;
                     colours_prev_overlap = colours_curr_primary;
                }


                // Next accumulated overlap becomes new current primary
                starts_curr_primary = std::move(starts_next_overlap_accum); // Efficiently move data
                ends_curr_primary = std::move(ends_next_overlap_accum);
                // Ensure times_next_overlap_accum (std::vector<double>) is moved to times_curr_primary (std::vector<double>)
                times_curr_primary = std::move(times_next_overlap_accum);
                colours_curr_primary = std::move(colours_next_overlap_accum);

                points_in_curr_primary_buf = ends_curr_primary.size(); // Size of what was next_overlap

                // Clear accumulator for next overlap (already moved from)
                starts_next_overlap_accum.clear(); ends_next_overlap_accum.clear();
                // Ensure times_next_overlap_accum (std::vector<double>) is cleared
                times_next_overlap_accum.clear();
                colours_next_overlap_accum.clear();
                points_in_next_overlap_buf = 0;

                first_block_processed = true;

                if (is_final_chunk_from_readply && points_in_curr_primary_buf == 0 && input_chunk_offset == chunk_ends.size()){
                    // All data from final chunk processed and shifted, and the new primary is empty.
                    // This means the last real block was processed.
                    break;
                }
            } else {
                // Not enough data to process a full block yet, and not the end of the file.
                // Break from while loop to get more data from readPly if current chunk is exhausted.
                if(input_chunk_offset == chunk_ends.size()) break;
            }
        } // end while(input_chunk_offset < chunk_ends.size())
    };

    // This lambda is a simplified version for ray::readPly, which then calls the main logic.
    // It needs to track if it's the last call from readPly.
    // ray::readPly's current interface doesn't explicitly signal the last chunk.
    // We need to modify readPly or infer it (e.g. if chunk_size < requested_chunk_size).
    // For now, let's assume a modified readPly or a wrapper that can signal this.
    // TEMPORARY: We'll call the lambda one more time after readPly finishes to flush remaining data.
    // This requires process_block_for_normals_lambda to handle is_final_chunk_from_readply = true correctly.

    size_t read_chunk_size_for_pass1 = 1000000; // Configurable: How many points readPly attempts to read each time

    // We need a way to pass the `is_final_chunk` signal.
    // Modifying `ray::readPly` is outside this scope.
    // Workaround: `ray::readPly` calls the lambda. After `ray::readPly` returns,
    // we explicitly call the lambda one last time with `is_final_chunk_from_readply = true`
    // and an empty input chunk to trigger processing of any remaining buffered points.

    auto readply_adapter_lambda =
        [&](std::vector<Eigen::Vector3d>& s, std::vector<Eigen::Vector3d>& e,
            std::vector<double>& t, // Ensure this is std::vector<double>
            std::vector<ray::RGBA>& c) {
        process_block_for_normals_lambda(s, e, t, c, false); // Assume not final during readPly calls
    };

    bool read_success = ray::readPly(input_ply_file, true, readply_adapter_lambda, 0.0, false, read_chunk_size_for_pass1);

    if (!read_success && !pass1_error_occurred) {
        std::cerr << "Error: ray::readPly failed for input file: " << input_ply_file << std::endl;
        out_intermediate_stream.close();
        return false;
    }

    // After readPly finishes, call lambda one last time with an empty chunk and final_chunk = true
    // to process any remaining data in buffers.
    if (!pass1_error_occurred) {
        std::vector<Eigen::Vector3d> empty_starts, empty_ends;
        std::vector<double> empty_times; // Ensure this is std::vector<double>
        std::vector<ray::RGBA> empty_colours;
        std::cout << "Flushing remaining data for Pass 1..." << std::endl;
        process_block_for_normals_lambda(empty_starts, empty_ends, empty_times, empty_colours, true);
    }

    if (pass1_error_occurred) { // Check again if error occurred during flushing
         std::cerr << "Error occurred during Pass 1 processing or flushing." << std::endl;
         out_intermediate_stream.close();
         return false;
    }

    if (!ray::finalizeIntermediatePass1PlyHeader(out_intermediate_stream, total_points_written_pass1, intermediate_vertex_count_pos)) {
        std::cerr << "Error: Failed to finalize intermediate PLY header for " << intermediate_ply_file << std::endl;
        out_intermediate_stream.close();
        return false;
    }

    out_intermediate_stream.close();
    std::cout << "Pass 1 completed. Total points written to intermediate file: " << total_points_written_pass1 << std::endl;
    return true;
}
